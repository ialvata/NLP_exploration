{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb85d050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models.doc2vec import Doc2Vec,TaggedDocument \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "import seaborn as sns\n",
    "from nltk.tokenize import casual_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "822d6a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5502123e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cores=multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e4efdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=r\"C:\\Users\\iavta\\Natural Language Processing\\Economics\\FED\\\\\"\n",
    "df_Fed_merged=pd.read_csv(path+\"Data - Clean\\\\\"+\"Fed_merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b69a5f37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 855 entries, 0 to 854\n",
      "Data columns (total 13 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   date                 855 non-null    object \n",
      " 1   link                 855 non-null    object \n",
      " 2   title                855 non-null    object \n",
      " 3   event                855 non-null    object \n",
      " 4   text                 855 non-null    object \n",
      " 5   location             855 non-null    object \n",
      " 6   DATE                 855 non-null    object \n",
      " 7   T5YIFR               855 non-null    float64\n",
      " 8   Changes of T5YIFR    855 non-null    float64\n",
      " 9   Distance to 2        855 non-null    float64\n",
      " 10  Changes in Distance  855 non-null    float64\n",
      " 11  Classes              855 non-null    float64\n",
      " 12  T5YIFR Lagged        855 non-null    float64\n",
      "dtypes: float64(6), object(7)\n",
      "memory usage: 87.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_Fed_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6041817",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>title</th>\n",
       "      <th>event</th>\n",
       "      <th>text</th>\n",
       "      <th>location</th>\n",
       "      <th>DATE</th>\n",
       "      <th>T5YIFR</th>\n",
       "      <th>Changes of T5YIFR</th>\n",
       "      <th>Distance to 2</th>\n",
       "      <th>Changes in Distance</th>\n",
       "      <th>Classes</th>\n",
       "      <th>T5YIFR Lagged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>2020-04-09</td>\n",
       "      <td>https://www.federalreserve.gov/newsevents/spee...</td>\n",
       "      <td>COVID-19 and the Economy</td>\n",
       "      <td>At the Hutchins Center on Fiscal and Monetary ...</td>\n",
       "      <td>Good morning. The challenge we face today is ...</td>\n",
       "      <td>D.C. (via webcast)</td>\n",
       "      <td>2020-04-09</td>\n",
       "      <td>1.56</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.44</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>2020-05-05</td>\n",
       "      <td>https://www.federalreserve.gov/newsevents/spee...</td>\n",
       "      <td>Welcoming Remarks for Investment Connection â...</td>\n",
       "      <td>At the \"Investment Connection â Response to ...</td>\n",
       "      <td>Good afternoon everyone. I greatly appreciate...</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>2020-05-05</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.51</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>2020-05-13</td>\n",
       "      <td>https://www.federalreserve.gov/newsevents/spee...</td>\n",
       "      <td>Current Economic Issues</td>\n",
       "      <td>At the Peterson Institute for International Ec...</td>\n",
       "      <td>The coronavirus has left a devastating human ...</td>\n",
       "      <td>D.C. (via webcast)</td>\n",
       "      <td>2020-05-13</td>\n",
       "      <td>1.43</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.03</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>2020-05-21</td>\n",
       "      <td>https://www.federalreserve.gov/newsevents/spee...</td>\n",
       "      <td>Opening Remarks Introductory remarks for the F...</td>\n",
       "      <td>At \"A Fed Listens Event: How Is COVID-19 Affec...</td>\n",
       "      <td>Good afternoon. I just want to say a few word...</td>\n",
       "      <td>D.C. (via webcast) (via webcast)  New York (vi...</td>\n",
       "      <td>2020-05-21</td>\n",
       "      <td>1.47</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>2020-06-16</td>\n",
       "      <td>https://www.federalreserve.gov/newsevents/spee...</td>\n",
       "      <td>U.S. Economic Outlook and Monetary Policy (via...</td>\n",
       "      <td>At the Foreign Policy Association, New York, N...</td>\n",
       "      <td>It is my pleasure to meet virtually this even...</td>\n",
       "      <td>New York</td>\n",
       "      <td>2020-06-16</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.48</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>2020-06-19</td>\n",
       "      <td>https://www.federalreserve.gov/newsevents/spee...</td>\n",
       "      <td>Introductory Comments The Adaptability of Stre...</td>\n",
       "      <td>At \"Building a Resilient Workforce,\" a video c...</td>\n",
       "      <td>Thank you, President Mester and Treye Johnson...</td>\n",
       "      <td>Ohio (via webcast) D.C.</td>\n",
       "      <td>2020-06-19</td>\n",
       "      <td>1.54</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.46</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date                                               link  \\\n",
       "849  2020-04-09  https://www.federalreserve.gov/newsevents/spee...   \n",
       "850  2020-05-05  https://www.federalreserve.gov/newsevents/spee...   \n",
       "851  2020-05-13  https://www.federalreserve.gov/newsevents/spee...   \n",
       "852  2020-05-21  https://www.federalreserve.gov/newsevents/spee...   \n",
       "853  2020-06-16  https://www.federalreserve.gov/newsevents/spee...   \n",
       "854  2020-06-19  https://www.federalreserve.gov/newsevents/spee...   \n",
       "\n",
       "                                                 title  \\\n",
       "849                           COVID-19 and the Economy   \n",
       "850  Welcoming Remarks for Investment Connection â...   \n",
       "851                            Current Economic Issues   \n",
       "852  Opening Remarks Introductory remarks for the F...   \n",
       "853  U.S. Economic Outlook and Monetary Policy (via...   \n",
       "854  Introductory Comments The Adaptability of Stre...   \n",
       "\n",
       "                                                 event  \\\n",
       "849  At the Hutchins Center on Fiscal and Monetary ...   \n",
       "850  At the \"Investment Connection â Response to ...   \n",
       "851  At the Peterson Institute for International Ec...   \n",
       "852  At \"A Fed Listens Event: How Is COVID-19 Affec...   \n",
       "853  At the Foreign Policy Association, New York, N...   \n",
       "854  At \"Building a Resilient Workforce,\" a video c...   \n",
       "\n",
       "                                                  text  \\\n",
       "849   Good morning. The challenge we face today is ...   \n",
       "850   Good afternoon everyone. I greatly appreciate...   \n",
       "851   The coronavirus has left a devastating human ...   \n",
       "852   Good afternoon. I just want to say a few word...   \n",
       "853   It is my pleasure to meet virtually this even...   \n",
       "854   Thank you, President Mester and Treye Johnson...   \n",
       "\n",
       "                                              location        DATE  T5YIFR  \\\n",
       "849                                 D.C. (via webcast)  2020-04-09    1.56   \n",
       "850                                           Missouri  2020-05-05    1.49   \n",
       "851                                 D.C. (via webcast)  2020-05-13    1.43   \n",
       "852  D.C. (via webcast) (via webcast)  New York (vi...  2020-05-21    1.47   \n",
       "853                                           New York  2020-06-16    1.52   \n",
       "854                            Ohio (via webcast) D.C.  2020-06-19    1.54   \n",
       "\n",
       "     Changes of T5YIFR  Distance to 2  Changes in Distance  Classes  \\\n",
       "849               0.05           0.44                -0.05      1.0   \n",
       "850               0.04           0.51                -0.04      1.0   \n",
       "851              -0.03           0.57                 0.03      2.0   \n",
       "852              -0.02           0.53                 0.02      2.0   \n",
       "853               0.04           0.48                -0.04      1.0   \n",
       "854               0.10           0.46                -0.10      1.0   \n",
       "\n",
       "     T5YIFR Lagged  \n",
       "849           1.51  \n",
       "850           1.45  \n",
       "851           1.46  \n",
       "852           1.49  \n",
       "853           1.48  \n",
       "854           1.44  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Fed_merged.iloc[-6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d74422df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(850, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_X=df_Fed_merged[[\"text\",\"T5YIFR Lagged\"]].iloc[:-5]\n",
    "# we're keeping the last 5 data points out, as our final test set.\n",
    "data_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e03122d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_X_testfinal=df_Fed_merged[[\"text\",\"T5YIFR Lagged\"]].iloc[-5:]\n",
    "data_X_testfinal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6ab9a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Time_Validation(datafr,labels,test_size=0.2):\n",
    "    train_index = list(range(int(len(datafr)-np.floor(test_size*len(datafr))+1)))\n",
    "    test_index =list(range(int(len(datafr)-np.floor(test_size*len(datafr))+1),len(datafr)))\n",
    "    return datafr.loc[train_index], datafr.loc[test_index],labels[train_index], labels[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44c86dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_corpus(array, tokens_only=False):\n",
    "    for i, text in enumerate(array):\n",
    "        tokens = casual_tokenize(text)\n",
    "        if tokens_only:\n",
    "            yield tokens\n",
    "        else:\n",
    "            # For training data (only), add tags\n",
    "            yield TaggedDocument(tokens, [i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be932370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_corpus_comp(array, tokens_only=False):\n",
    "    [casual_tokenize(text) if tokens_only \n",
    "     else TaggedDocument(casual_tokenize(text), [i]) for i, text in enumerate(array)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a535a77e",
   "metadata": {},
   "source": [
    "# Fed - LGBM - Classification - Naive Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6aecfc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "import optuna\n",
    "from sklearn.metrics import roc_auc_score,classification_report\n",
    "from sklearn.metrics import confusion_matrix, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4512866",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(850,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=np.asarray(df_Fed_merged[\"Classes\"].astype(\"int\"))[:-5]\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ceedba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_testfinal=np.asarray(df_Fed_merged[\"Classes\"].astype(\"int\"))[-5:]\n",
    "labels_testfinal.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c2b6b3",
   "metadata": {},
   "source": [
    "## Preparing data for LGBM dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61367255",
   "metadata": {},
   "source": [
    "Usually, the spliting data stage should be inside the Optuna function that we will optimise. However, since we're in a time series setting, with a given test_size, we're going to have the same validation set. Hence, it seems that we can accelerate the optuna process, by leaving the data out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7113aff",
   "metadata": {},
   "source": [
    "Cross-Validation is not possible in a Time-Series setting.\n",
    "The best we can do is do a stepwise n-lag prediction, and compute a (cumulative) metric for our process of prediction, e.g. RMSE. This will imply to reestimate the word embeddings at every period, which in my PC is very costly...  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df2a8d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we have validation(test) sets\n",
    "data_X_train, data_X_test, labels_train, labels_test=Time_Validation(data_X,labels,\n",
    "                                                                         test_size=0.05)\n",
    "train_size , _= data_X_train.shape\n",
    "test_size , _= data_X_test.shape\n",
    "\n",
    "\n",
    "corpus_train=list(prepare_corpus(data_X_train[\"text\"]))\n",
    "\n",
    "#instantiating Doc2Vec class\n",
    "vector_size = 20\n",
    "epochs = 25\n",
    "embedding_doc2vec=Doc2Vec(vector_size=vector_size, min_count=2, epochs=epochs, \n",
    "                          workers=num_cores)\n",
    "\n",
    "#building and training doc2vec model\n",
    "embedding_doc2vec.build_vocab(corpus_train)\n",
    "\n",
    "embedding_doc2vec.train(corpus_train,total_examples=embedding_doc2vec.corpus_count,\n",
    "                       epochs=embedding_doc2vec.epochs)\n",
    "\n",
    "# preparing X_train data\n",
    "df_train=pd.DataFrame(np.array([embedding_doc2vec.dv[i] for i in range(train_size)]),\n",
    "                  columns=[\"doc\"+str(i) for i in range(vector_size)])\n",
    "\n",
    "df_train[\"T5YIFR Lagged\"]=data_X_train[\"T5YIFR Lagged\"]\n",
    "\n",
    "# preparing X_test data\n",
    "corpus_test=list(prepare_corpus(data_X_test[\"text\"],tokens_only=True))\n",
    "\n",
    "df_test=pd.DataFrame(np.array([embedding_doc2vec.infer_vector(corpus_test[i])\n",
    "                            for i in range(test_size)]),\n",
    "                  columns=[\"doc_test\"+str(i) for i in range(vector_size)])\n",
    "df_test[\"T5YIFR Lagged\"]=data_X_test[\"T5YIFR Lagged\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "933b327f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "   \n",
    "    # uncomment the line below, if you want to work directly with the best model\n",
    "    # global lgbmc \n",
    "    \n",
    "    dtrain = lgb.Dataset(df_train, label=labels_train)\n",
    " \n",
    "    param = {\n",
    "        'objective': 'multiclass', # we're in a multiclass classification problem\n",
    "        'num_class':3, \n",
    "        'metric': 'multi_logloss',\n",
    "        \"verbosity\": -1,\n",
    "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 502,10),\n",
    "        'max_depth': trial.suggest_categorical('max_depth', [10,20,100]),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10,3),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100,5)\n",
    "    }\n",
    "    # Add a callback for pruning = early stopping.\n",
    "    pruning_callback = optuna.integration.LightGBMPruningCallback(trial, \"multi_logloss\")\n",
    "    \n",
    "    lgbmc = lgb.train(param, dtrain) #verbose_eval=False)\n",
    "    \n",
    "    predictions=lgbmc.predict(df_test) # returns the class probabilities\n",
    "    \n",
    "    crit = roc_auc_score(labels_test,predictions, multi_class=\"ovr\") \n",
    "    \n",
    "    return crit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca602a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this callback will check if the model is the best,\n",
    "# and return a global variable with the best model\n",
    "\n",
    "def best_callback(study, trial):\n",
    "    pass\n",
    "# Uncomment bellow is you want the best model to be returned\n",
    "#    global best_booster # best model to be returned\n",
    "    \n",
    "    # study is the optuna study to be created below\n",
    "#    if study.best_trial.number == trial.number:\n",
    "#        best_booster = lgbmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3be92b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(pruner=optuna.pruners.MedianPruner(n_warmup_steps=10),\n",
    "                            direction='maximize')\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "study.optimize(objective, n_trials=250, callbacks=[best_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e75dae4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Params: \n",
      "    lambda_l1: 5.853623660010822e-05\n",
      "    lambda_l2: 4.343021754023105\n",
      "    num_leaves: 252\n",
      "    max_depth: 20\n",
      "    feature_fraction: 0.5440941567177511\n",
      "    bagging_fraction: 0.6249489616647574\n",
      "    bagging_freq: 7\n",
      "    min_child_samples: 35\n"
     ]
    }
   ],
   "source": [
    "# lgbm_trial will have the parameters of the best_booster\n",
    "lgbm_trial= study.best_trial\n",
    "print(\"  Params: \")\n",
    "for key, value in lgbm_trial.params.items():\n",
    "       print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c4465920",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for key, value in best_booster.params.items():\n",
    "#       print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1dc4d972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5440941567177511, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5440941567177511\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.853623660010822e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.853623660010822e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6249489616647574, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6249489616647574\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.343021754023105, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.343021754023105\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    }
   ],
   "source": [
    "# I could have used the best_booster model, and then I wouldn't need to run LGBMClassifier\n",
    "# However, then I would have to change the code below, \n",
    "# since it would only output class probabilities.\n",
    "best_lgbm=LGBMClassifier(**lgbm_trial.params)\n",
    "best_lgbm.fit(df_train,labels_train)\n",
    "\n",
    "\n",
    "# We're using the same test \n",
    "predictions=best_lgbm.predict(df_test)\n",
    "probabilities=best_lgbm.predict_proba(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e9e08ad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  1,  6],\n",
       "       [ 2, 10,  6],\n",
       "       [ 1,  3, 11]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(labels_test, predictions)\n",
    "#  i-th row and j-th column entry indicates the number of samples \n",
    "#  with true label being i-th class and predicted label being j-th class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11ee253",
   "metadata": {},
   "source": [
    "If we compare to the confusion_matrix without optuna, we can see that lgbm no longer tends to over predict class 2. However, due to class imbalance, we still perform poorly (but less) on class 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e4de901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7030806954719999"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(labels_test,probabilities, multi_class=\"ovr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebecc8e",
   "metadata": {},
   "source": [
    "Also, roc_auc_score is now better than what we got from the default LGBM + WE  in the previous notebook. \n",
    "\n",
    "Still, we're analysing the performance of the model on the dataset on which it was trained. We need to analyse its performance on the unseen data, like below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af58709b",
   "metadata": {},
   "outputs": [],
   "source": [
    "testfinal = list(prepare_corpus(data_X_testfinal[\"text\"],tokens_only=True))\n",
    "testfinal=pd.DataFrame(np.array([embedding_doc2vec.infer_vector(i)\n",
    "                                for i in testfinal]))\n",
    "testfinal[\"T5YIFR Lagged\"]=data_X_testfinal[\"T5YIFR Lagged\"]\n",
    "\n",
    "predictions_final=best_lgbm.predict(testfinal)\n",
    "probabilities_final=best_lgbm.predict_proba(testfinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d9c5a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 0],\n",
       "       [0, 2]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(labels_testfinal, predictions_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4bf30b",
   "metadata": {},
   "source": [
    "Not bad (and a bit lucky), specially since the last 5 data points are 1 to 2 months apart approx. from the last observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ddaec985",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(labels_testfinal, predictions_final,adjusted=True)\n",
    "# accuracy score for imbalanced classes\n",
    "# 0 for a random classifier\n",
    "# 1 for a perfect classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a22340",
   "metadata": {},
   "source": [
    "In a world where I had a better laptop, I would have saved a bigger test set, and then analyse iteratively, the performance for 1-lag, 2-lag and 5-lag predictions. Also, Since classes are imbalanced, and the finaltest set is small, there's no point in running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "04abd15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc_auc_score(labels_testfinal,probabilities, multi_class=\"ovr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5fc87afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples=[\n",
    "    'Trust us, inflation will be 2%',\n",
    "    'We are unsure whether it will be 2%',\n",
    "    'Inflation will be higher than 2%',\n",
    "    'Inflation will be lower than 2%',\n",
    "]\n",
    "\n",
    "examples_trans = list(prepare_corpus(examples,tokens_only=True))\n",
    "examples_trans=pd.DataFrame(np.array([embedding_doc2vec.infer_vector(i)\n",
    "                                for i in examples_trans]))\n",
    "\n",
    "examples_trans[\"T5YIFR Lagged\"]=[1,2,1,3] \n",
    "# I've tried several different vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a06f8d6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Trust us, inflation will be 2% Predicted Class: 1 \n",
      "\n",
      "Sentence: We are unsure whether it will be 2% Predicted Class: 1 \n",
      "\n",
      "Sentence: Inflation will be higher than 2% Predicted Class: 1 \n",
      "\n",
      "Sentence: Inflation will be lower than 2% Predicted Class: 1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = best_lgbm.predict(examples_trans)\n",
    "# 0 ->  no change\n",
    "# 2 -> increased the distance relative to objective of 2\n",
    "# 1 -> decreased the distance relative to objective of 2\n",
    "\n",
    "\n",
    "for sent,pred in zip(examples,predictions):\n",
    "    print(\"Sentence: {0} Predicted Class: {1} \\n\".format(sent,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f441095",
   "metadata": {},
   "source": [
    "# Fed - LGBM - Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6944cceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8ed6d15b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(850,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target=np.asarray(df_Fed_merged[\"T5YIFR\"])[:-5]\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "893aca04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_testfinal=np.asarray(df_Fed_merged[\"T5YIFR\"])[-5:]\n",
    "target_testfinal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aea2802a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X_train, data_X_test, target_train, target_test=Time_Validation(data_X,target,test_size=0.05)\n",
    "train_size , _= data_X_train.shape\n",
    "test_size , _= data_X_test.shape\n",
    "\n",
    "corpus_train=list(prepare_corpus(data_X_train[\"text\"]))\n",
    "\n",
    "#instantiating Doc2Vec class\n",
    "vector_size = 20\n",
    "epochs = 25\n",
    "embedding_doc2vec=Doc2Vec(vector_size=vector_size, min_count=2, epochs=epochs, \n",
    "                          workers=num_cores)\n",
    "\n",
    "#building and training model\n",
    "embedding_doc2vec.build_vocab(corpus_train)\n",
    "\n",
    "embedding_doc2vec.train(corpus_train,total_examples=embedding_doc2vec.corpus_count,\n",
    "                       epochs=embedding_doc2vec.epochs)\n",
    "\n",
    "# embedding_doc2vec.dv is gensim keyedvector data type,\n",
    "# with each component beint the document vector (dv) obtained from training.\n",
    "df_train=pd.DataFrame(np.array([embedding_doc2vec.dv[i] for i in range(train_size)]),\n",
    "                      columns=[\"doc\"+str(i) for i in range(vector_size)])\n",
    "\n",
    "df_train[\"T5YIFR Lagged\"]=data_X_train[\"T5YIFR Lagged\"]\n",
    "\n",
    "# creating validation test set.\n",
    "corpus_test=list(prepare_corpus(data_X_test[\"text\"],tokens_only=True))\n",
    "\n",
    "df_test=pd.DataFrame(np.array([embedding_doc2vec.infer_vector(corpus_test[i])\n",
    "                                for i in range(test_size)]),\n",
    "                      columns=[\"doc_test\"+str(i) for i in range(vector_size)])\n",
    "df_test[\"T5YIFR Lagged\"]=data_X_test[\"T5YIFR Lagged\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "120e4462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_saved_LGBM=path+\"Saved Models\\\\\"+\"Embedding-Doc2Vec\\\\\"\n",
    "# we need to create the directory before running the command below\n",
    "# embedding_doc2vec.save(path_saved_LGBM+\"embedding_doc2vec_regressor\")\n",
    "# to load, uncomment the line below\n",
    "# embedding_doc2vec = Doc2Vec.load(path_saved_LGBM+\"embedding_doc2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cd60f11f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def objective_reg(trial):\n",
    "   \n",
    "    # uncomment the line below, if you want to work directly with the best model\n",
    "    # global lgbmc \n",
    "    \n",
    "    dtrain = lgb.Dataset(df_train, label=labels_train)\n",
    " \n",
    "    param = {\n",
    "        'objective': 'regression', # we're in a regression problem\n",
    "        'metric': 'l2',\n",
    "        \"verbosity\": -1,\n",
    "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 502,10),\n",
    "        'max_depth': trial.suggest_categorical('max_depth', [10,20,100]),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10,3),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100,5)\n",
    "    }\n",
    "    \n",
    "    # Add a callback for pruning = early stopping.\n",
    "    pruning_callback = optuna.integration.LightGBMPruningCallback(trial, \"l2\")\n",
    "    \n",
    "    lgbmc = lgb.train(param, dtrain)\n",
    "    \n",
    "    predictions=lgbmc.predict(df_test) # returns predictions for IE \n",
    "    \n",
    "    crit = lgbmc.score(df_test,target_test) # Regression score\n",
    "    \n",
    "    return crit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "516df4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(pruner=optuna.pruners.MedianPruner(n_warmup_steps=10),\n",
    "                            direction='maximize')\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "study.optimize(objective, n_trials=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "73a0bf4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Params: \n",
      "    lambda_l1: 0.0004907685962644185\n",
      "    lambda_l2: 0.04017199105504725\n",
      "    num_leaves: 242\n",
      "    max_depth: 10\n",
      "    feature_fraction: 0.6074944699115936\n",
      "    bagging_fraction: 0.6492544671270084\n",
      "    bagging_freq: 10\n",
      "    min_child_samples: 15\n"
     ]
    }
   ],
   "source": [
    "# lgbm_trial will have the parameters of the best_booster\n",
    "lgbm_trial= study.best_trial\n",
    "print(\"  Params: \")\n",
    "for key, value in lgbm_trial.params.items():\n",
    "       print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e555dcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_reg=LGBMRegressor(**lgbm_trial.params)\n",
    "lgbm_reg.fit(df_train,target_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aaee02df",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_reg=lgbm_reg.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c86b4574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  -6.020079508828599\n",
      "\n",
      " RMSE:  0.22733524991908935\n"
     ]
    }
   ],
   "source": [
    "accuracy_reg = lgbm_reg.score(df_test,target_test)\n",
    "print(\"Score: \", accuracy_reg) #\n",
    "\n",
    "rmse = np.sqrt(np.mean((predictions_reg-target_test)**2))\n",
    "print(\"\\n RMSE: \", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0c13a4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Trust us, inflation will be 2% Predicted Class: 2.5733475052838215 \n",
      "\n",
      "Sentence: We are unsure whether it will be 2% Predicted Class: 2.7140534025185885 \n",
      "\n",
      "Sentence: Inflation will be higher than 2% Predicted Class: 2.6818045411951497 \n",
      "\n",
      "Sentence: Inflation will be lower than 2% Predicted Class: 2.5620249697326085 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "examples_trans = list(prepare_corpus(examples,tokens_only=True))\n",
    "examples_trans=pd.DataFrame(np.array([embedding_doc2vec.infer_vector(i)\n",
    "                                for i in examples_trans]))\n",
    "\n",
    "examples_trans[\"T5YIFR Lagged\"]=[3,3,3,3] \n",
    "# I've tried several different vectors\n",
    "\n",
    "predictions = lgbm_reg.predict(examples_trans)\n",
    "# 0 ->  no change\n",
    "# 2 -> increased the distance relative to objective of 2\n",
    "# 1 -> decreased the distance relative to objective of 2\n",
    "for sent,pred in zip(examples,predictions):\n",
    "    print(\"Sentence: {0} Predicted Class: {1} \\n\".format(sent,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f32edf",
   "metadata": {},
   "source": [
    "Let's assume the baseline is the \"Trust us\" sentence. \n",
    "\n",
    "With uncertainty, and when the CB states that inflation will be bigger, the model predicts a higher inflation than the baseline.\n",
    "\n",
    "When the CB states inflation will be lower, the model predicts that inflation will be lower than the baseline model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
