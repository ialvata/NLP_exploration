{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb85d050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from gensim.models.doc2vec import Doc2Vec,TaggedDocument \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "import seaborn as sns\n",
    "from nltk.tokenize import casual_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "822d6a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5502123e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cores=multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e4efdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=r\"C:\\Users\\iavta\\Natural Language Processing\\Economics\\FED\\\\\"\n",
    "df_Fed_merged=pd.read_csv(path+\"Data - Clean\\\\\"+\"Fed_merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b69a5f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 855 entries, 0 to 854\n",
      "Data columns (total 13 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   date                 855 non-null    object \n",
      " 1   link                 855 non-null    object \n",
      " 2   title                855 non-null    object \n",
      " 3   event                855 non-null    object \n",
      " 4   text                 855 non-null    object \n",
      " 5   location             855 non-null    object \n",
      " 6   DATE                 855 non-null    object \n",
      " 7   T5YIFR               855 non-null    float64\n",
      " 8   Changes of T5YIFR    855 non-null    float64\n",
      " 9   Distance to 2        855 non-null    float64\n",
      " 10  Changes in Distance  855 non-null    float64\n",
      " 11  Classes              855 non-null    float64\n",
      " 12  T5YIFR Lagged        855 non-null    float64\n",
      "dtypes: float64(6), object(7)\n",
      "memory usage: 87.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_Fed_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d74422df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X=df_Fed_merged[[\"text\",\"T5YIFR Lagged\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6ab9a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Time_Validation(datafr,labels,test_size=0.2):\n",
    "    train_index = list(range(int(len(datafr)-np.floor(test_size*len(datafr))+1)))\n",
    "    test_index =list(range(int(len(datafr)-np.floor(test_size*len(datafr))+1),len(datafr)))\n",
    "    return datafr.loc[train_index], datafr.loc[test_index],labels[train_index], labels[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44c86dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_corpus(array, tokens_only=False):\n",
    "    for i, text in enumerate(array):\n",
    "        tokens = casual_tokenize(text)\n",
    "        if tokens_only:\n",
    "            yield tokens\n",
    "        else:\n",
    "            # For training data (only), add tags\n",
    "            yield TaggedDocument(tokens, [i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be932370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_corpus_comp(array, tokens_only=False):\n",
    "    [casual_tokenize(text) if tokens_only \n",
    "     else TaggedDocument(casual_tokenize(text), [i]) for i, text in enumerate(array)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a535a77e",
   "metadata": {},
   "source": [
    "# Fed - LGBM - Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6aecfc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4512866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(855,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=np.asarray(df_Fed_merged[\"Classes\"].astype(\"int\"))\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bc15bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X_train, data_X_test, labels_train, labels_test=Time_Validation(data_X,labels,test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "091cc772",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_size , _= data_X_train.shape\n",
    "test_size , _= data_X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a26a1120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.4 s ± 1.75 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit corpus_train=list(prepare_corpus(data_X_train[\"text\"])) \n",
    "# yield performs very similarly to list comprehension on avg, but with less variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "33bec08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.6 s ± 2.32 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit corpus_train=prepare_corpus_comp(data_X_train[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e73269b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_train=list(prepare_corpus(data_X_train[\"text\"]))\n",
    "\n",
    "#instantiating Doc2Vec class\n",
    "vector_size=50\n",
    "embedding_doc2vec=Doc2Vec(vector_size=vector_size, min_count=2, epochs=40, workers=num_cores)\n",
    "\n",
    "#building and training model\n",
    "embedding_doc2vec.build_vocab(corpus_train)\n",
    "\n",
    "embedding_doc2vec.train(corpus_train,total_examples=embedding_doc2vec.corpus_count,\n",
    "                       epochs=embedding_doc2vec.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a5185fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_saved_LGBM=path+\"Saved Models\\\\\"+\"Embedding-Doc2Vec\\\\\"\n",
    "# we need to create the directory before running the command below\n",
    "embedding_doc2vec.save(path_saved_LGBM+\"embedding_doc2vec_classifier\")\n",
    "# to load, uncomment the line below\n",
    "# embedding_doc2vec = Doc2Vec.load(path_saved_LGBM+\"embedding_doc2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7016f549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_doc2vec.dv is gensim keyedvector data type,\n",
    "# with each component beint the document vector (dv) obtained from training\n",
    "\n",
    "df_train=pd.DataFrame(np.array([embedding_doc2vec.dv[i] for i in range(train_size)]),\n",
    "                      columns=[\"doc\"+str(i) for i in range(vector_size)])\n",
    "\n",
    "df_train[\"T5YIFR Lagged\"]=data_X_train[\"T5YIFR Lagged\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c8b1e71d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc0</th>\n",
       "      <th>doc1</th>\n",
       "      <th>doc2</th>\n",
       "      <th>doc3</th>\n",
       "      <th>doc4</th>\n",
       "      <th>doc5</th>\n",
       "      <th>doc6</th>\n",
       "      <th>doc7</th>\n",
       "      <th>doc8</th>\n",
       "      <th>doc9</th>\n",
       "      <th>...</th>\n",
       "      <th>doc41</th>\n",
       "      <th>doc42</th>\n",
       "      <th>doc43</th>\n",
       "      <th>doc44</th>\n",
       "      <th>doc45</th>\n",
       "      <th>doc46</th>\n",
       "      <th>doc47</th>\n",
       "      <th>doc48</th>\n",
       "      <th>doc49</th>\n",
       "      <th>T5YIFR Lagged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.488771</td>\n",
       "      <td>-2.538723</td>\n",
       "      <td>-2.873959</td>\n",
       "      <td>-3.112880</td>\n",
       "      <td>1.295459</td>\n",
       "      <td>-5.347455</td>\n",
       "      <td>-1.853269</td>\n",
       "      <td>1.875832</td>\n",
       "      <td>-2.946009</td>\n",
       "      <td>-1.938024</td>\n",
       "      <td>...</td>\n",
       "      <td>1.638317</td>\n",
       "      <td>1.559110</td>\n",
       "      <td>-0.896035</td>\n",
       "      <td>1.508760</td>\n",
       "      <td>-1.582389</td>\n",
       "      <td>-0.960373</td>\n",
       "      <td>-0.457239</td>\n",
       "      <td>0.185955</td>\n",
       "      <td>-0.440521</td>\n",
       "      <td>2.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.726032</td>\n",
       "      <td>-2.394056</td>\n",
       "      <td>0.864733</td>\n",
       "      <td>-3.695441</td>\n",
       "      <td>-0.792782</td>\n",
       "      <td>-1.818849</td>\n",
       "      <td>-0.164185</td>\n",
       "      <td>3.601535</td>\n",
       "      <td>-3.283093</td>\n",
       "      <td>1.250679</td>\n",
       "      <td>...</td>\n",
       "      <td>0.699519</td>\n",
       "      <td>-0.904267</td>\n",
       "      <td>-1.933889</td>\n",
       "      <td>0.610341</td>\n",
       "      <td>-3.263781</td>\n",
       "      <td>0.654586</td>\n",
       "      <td>-0.718167</td>\n",
       "      <td>0.417214</td>\n",
       "      <td>-0.467186</td>\n",
       "      <td>2.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.687704</td>\n",
       "      <td>-4.629267</td>\n",
       "      <td>0.523481</td>\n",
       "      <td>-0.605821</td>\n",
       "      <td>0.672305</td>\n",
       "      <td>-0.483044</td>\n",
       "      <td>-1.052666</td>\n",
       "      <td>1.835982</td>\n",
       "      <td>-1.098219</td>\n",
       "      <td>-0.777684</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.029462</td>\n",
       "      <td>-0.724765</td>\n",
       "      <td>-0.600786</td>\n",
       "      <td>-0.079076</td>\n",
       "      <td>-1.886830</td>\n",
       "      <td>0.452371</td>\n",
       "      <td>-2.356006</td>\n",
       "      <td>0.255244</td>\n",
       "      <td>-0.792763</td>\n",
       "      <td>2.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.668830</td>\n",
       "      <td>-4.357888</td>\n",
       "      <td>0.393071</td>\n",
       "      <td>-1.464142</td>\n",
       "      <td>-2.265313</td>\n",
       "      <td>-0.343736</td>\n",
       "      <td>1.392451</td>\n",
       "      <td>0.493134</td>\n",
       "      <td>-2.076980</td>\n",
       "      <td>-1.469864</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.001611</td>\n",
       "      <td>1.527520</td>\n",
       "      <td>-1.647809</td>\n",
       "      <td>-1.148558</td>\n",
       "      <td>-1.388819</td>\n",
       "      <td>-0.790706</td>\n",
       "      <td>-3.317306</td>\n",
       "      <td>3.524722</td>\n",
       "      <td>-1.668324</td>\n",
       "      <td>2.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.172548</td>\n",
       "      <td>-2.807615</td>\n",
       "      <td>-3.059715</td>\n",
       "      <td>-2.474043</td>\n",
       "      <td>0.305137</td>\n",
       "      <td>-5.513704</td>\n",
       "      <td>-2.642413</td>\n",
       "      <td>2.272916</td>\n",
       "      <td>-2.565372</td>\n",
       "      <td>-0.554859</td>\n",
       "      <td>...</td>\n",
       "      <td>2.796026</td>\n",
       "      <td>1.482919</td>\n",
       "      <td>0.309122</td>\n",
       "      <td>-0.407435</td>\n",
       "      <td>-1.756124</td>\n",
       "      <td>-0.040547</td>\n",
       "      <td>0.077617</td>\n",
       "      <td>-0.188567</td>\n",
       "      <td>-0.838324</td>\n",
       "      <td>2.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       doc0      doc1      doc2      doc3      doc4      doc5      doc6  \\\n",
       "0 -2.488771 -2.538723 -2.873959 -3.112880  1.295459 -5.347455 -1.853269   \n",
       "1 -2.726032 -2.394056  0.864733 -3.695441 -0.792782 -1.818849 -0.164185   \n",
       "2 -0.687704 -4.629267  0.523481 -0.605821  0.672305 -0.483044 -1.052666   \n",
       "3 -1.668830 -4.357888  0.393071 -1.464142 -2.265313 -0.343736  1.392451   \n",
       "4 -1.172548 -2.807615 -3.059715 -2.474043  0.305137 -5.513704 -2.642413   \n",
       "\n",
       "       doc7      doc8      doc9  ...     doc41     doc42     doc43     doc44  \\\n",
       "0  1.875832 -2.946009 -1.938024  ...  1.638317  1.559110 -0.896035  1.508760   \n",
       "1  3.601535 -3.283093  1.250679  ...  0.699519 -0.904267 -1.933889  0.610341   \n",
       "2  1.835982 -1.098219 -0.777684  ... -1.029462 -0.724765 -0.600786 -0.079076   \n",
       "3  0.493134 -2.076980 -1.469864  ... -2.001611  1.527520 -1.647809 -1.148558   \n",
       "4  2.272916 -2.565372 -0.554859  ...  2.796026  1.482919  0.309122 -0.407435   \n",
       "\n",
       "      doc45     doc46     doc47     doc48     doc49  T5YIFR Lagged  \n",
       "0 -1.582389 -0.960373 -0.457239  0.185955 -0.440521           2.13  \n",
       "1 -3.263781  0.654586 -0.718167  0.417214 -0.467186           2.14  \n",
       "2 -1.886830  0.452371 -2.356006  0.255244 -0.792763           2.19  \n",
       "3 -1.388819 -0.790706 -3.317306  3.524722 -1.668324           2.20  \n",
       "4 -1.756124 -0.040547  0.077617 -0.188567 -0.838324           2.24  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "872bf53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier()"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbmc=LGBMClassifier();\n",
    "lgbmc.fit(df_train,labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1efa9980",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_test=list(prepare_corpus(data_X_test[\"text\"],tokens_only=True))\n",
    "\n",
    "df_test=pd.DataFrame(np.array([embedding_doc2vec.infer_vector(corpus_test[i])\n",
    "                                for i in range(test_size)]),\n",
    "                      columns=[\"doc_test\"+str(i) for i in range(vector_size)])\n",
    "df_test[\"T5YIFR Lagged\"]=data_X_test[\"T5YIFR Lagged\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1dc4d972",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=lgbmc.predict(df_test)\n",
    "probabilities=lgbmc.predict_proba(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c662adc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, balanced_accuracy_score\n",
    "from sklearn.metrics import roc_auc_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5e9e08ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 4],\n",
       "       [2, 7, 9],\n",
       "       [0, 9, 7]], dtype=int64)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(labels_test, predictions)\n",
    "#  i-th row and j-th column entry indicates the number of samples \n",
    "#  with true label being i-th class and predicted label being j-th class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11ee253",
   "metadata": {},
   "source": [
    "We can see that lgbm still tends to predict class 2 (from 0,1 and 2) too many times, but less than if we hadn't used the doc2vec embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ddaec985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.015376984126984098"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(labels_test, predictions,adjusted=True) \n",
    "# accuracy score for imbalanced classes\n",
    "# 0 for a random classifier\n",
    "# 1 for a perfect classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b0c9fcd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5255554202357271"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(labels_test,probabilities, multi_class=\"ovr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fbab77",
   "metadata": {},
   "source": [
    "This value for roc seems to indicate performance is worse than a random classifier which would get a roc of 0.5...\n",
    "\n",
    "I think I need to do a random grid search to the parameters of the LGBM classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5fc87afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples=[\n",
    "    'Trust us, inflation will be 2%',\n",
    "    'We are unsure whether it will be 2%',\n",
    "    'Inflation will be higher than 2%',\n",
    "    'Inflation will be lower than 2%',\n",
    "]\n",
    "\n",
    "examples_trans = list(prepare_corpus(examples,tokens_only=True))\n",
    "examples_trans=pd.DataFrame(np.array([embedding_doc2vec.infer_vector(i)\n",
    "                                for i in examples_trans]))\n",
    "\n",
    "examples_trans[\"T5YIFR Lagged\"]=[3,3,3,3] \n",
    "# I've tried several different vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a06f8d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Trust us, inflation will be 2% Predicted Class: 2 \n",
      "\n",
      "Sentence: We are unsure whether it will be 2% Predicted Class: 2 \n",
      "\n",
      "Sentence: Inflation will be higher than 2% Predicted Class: 0 \n",
      "\n",
      "Sentence: Inflation will be lower than 2% Predicted Class: 0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = lgbmc.predict(examples_trans)\n",
    "# 0 ->  no change\n",
    "# 2 -> increased the distance relative to objective of 2\n",
    "# 1 -> decreased the distance relative to objective of 2\n",
    "\n",
    "\n",
    "for sent,pred in zip(examples,predictions):\n",
    "    print(\"Sentence: {0} Predicted Class: {1} \\n\".format(sent,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f441095",
   "metadata": {},
   "source": [
    "# Fed - LGBM - Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6944cceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8ed6d15b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(855,)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target=np.asarray(df_Fed_merged[\"T5YIFR\"])\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f5e62ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X_train, data_X_test, target_train, target_test=Time_Validation(data_X,target,test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "aea2802a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size , _= data_X_train.shape\n",
    "test_size , _= data_X_test.shape\n",
    "\n",
    "corpus_train=list(prepare_corpus(data_X_train[\"text\"]))\n",
    "\n",
    "#instantiating Doc2Vec class\n",
    "vector_size=50\n",
    "embedding_doc2vec=Doc2Vec(vector_size=vector_size, min_count=2, epochs=40, workers=num_cores)\n",
    "\n",
    "#building and training model\n",
    "embedding_doc2vec.build_vocab(corpus_train)\n",
    "\n",
    "embedding_doc2vec.train(corpus_train,total_examples=embedding_doc2vec.corpus_count,\n",
    "                       epochs=embedding_doc2vec.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "120e4462",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_saved_LGBM=path+\"Saved Models\\\\\"+\"Embedding-Doc2Vec\\\\\"\n",
    "# we need to create the directory before running the command below\n",
    "embedding_doc2vec.save(path_saved_LGBM+\"embedding_doc2vec_regressor\")\n",
    "# to load, uncomment the line below\n",
    "# embedding_doc2vec = Doc2Vec.load(path_saved_LGBM+\"embedding_doc2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d00dd2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_doc2vec.dv is gensim keyedvector data type,\n",
    "# with each component beint the document vector (dv) obtained from training\n",
    "\n",
    "df_train=pd.DataFrame(np.array([embedding_doc2vec.dv[i] for i in range(train_size)]),\n",
    "                      columns=[\"doc\"+str(i) for i in range(vector_size)])\n",
    "\n",
    "df_train[\"T5YIFR Lagged\"]=data_X_train[\"T5YIFR Lagged\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e555dcee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor()"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_reg=LGBMRegressor()\n",
    "lgbm_reg.fit(df_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "edf0ae9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_test=list(prepare_corpus(data_X_test[\"text\"],tokens_only=True))\n",
    "\n",
    "df_test=pd.DataFrame(np.array([embedding_doc2vec.infer_vector(corpus_test[i])\n",
    "                                for i in range(test_size)]),\n",
    "                      columns=[\"doc_test\"+str(i) for i in range(vector_size)])\n",
    "df_test[\"T5YIFR Lagged\"]=data_X_test[\"T5YIFR Lagged\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "aaee02df",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_reg=lgbm_reg.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c86b4574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.104107956812326\n",
      "0.22814947914167963\n"
     ]
    }
   ],
   "source": [
    "accuracy_reg = lgbm_reg.score(df_test,target_test)\n",
    "print(accuracy_reg) #\n",
    "\n",
    "rmse = np.sqrt(np.mean((predictions_reg-target_test)**2))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0c13a4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Trust us, inflation will be 2% Predicted Class: 2.849320202723464 \n",
      "\n",
      "Sentence: We are unsure whether it will be 2% Predicted Class: 2.881743185562295 \n",
      "\n",
      "Sentence: Inflation will be higher than 2% Predicted Class: 2.8730307640072703 \n",
      "\n",
      "Sentence: Inflation will be lower than 2% Predicted Class: 2.873259804161956 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "examples_trans = list(prepare_corpus(examples,tokens_only=True))\n",
    "examples_trans=pd.DataFrame(np.array([embedding_doc2vec.infer_vector(i)\n",
    "                                for i in examples_trans]))\n",
    "\n",
    "examples_trans[\"T5YIFR Lagged\"]=[3,3,3,3] \n",
    "# I've tried several different vectors\n",
    "\n",
    "predictions = lgbm_reg.predict(examples_trans)\n",
    "# 0 ->  no change\n",
    "# 2 -> increased the distance relative to objective of 2\n",
    "# 1 -> decreased the distance relative to objective of 2\n",
    "for sent,pred in zip(examples,predictions):\n",
    "    print(\"Sentence: {0} Predicted Class: {1} \\n\".format(sent,pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
