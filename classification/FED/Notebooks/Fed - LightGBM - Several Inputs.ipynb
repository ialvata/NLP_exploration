{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb85d050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3e4efdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=r\"C:\\Users\\iavta\\Natural Language Processing\\Economics\\FED\\\\\"\n",
    "df_Fed_merged=pd.read_csv(path+\"Data - Clean\\\\\"+\"Fed_merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b69a5f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 855 entries, 0 to 854\n",
      "Data columns (total 13 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   date                 855 non-null    object \n",
      " 1   link                 855 non-null    object \n",
      " 2   title                855 non-null    object \n",
      " 3   event                855 non-null    object \n",
      " 4   text                 855 non-null    object \n",
      " 5   location             855 non-null    object \n",
      " 6   DATE                 855 non-null    object \n",
      " 7   T5YIFR               855 non-null    float64\n",
      " 8   Changes of T5YIFR    855 non-null    float64\n",
      " 9   Distance to 2        855 non-null    float64\n",
      " 10  Changes in Distance  855 non-null    float64\n",
      " 11  Classes              855 non-null    float64\n",
      " 12  T5YIFR Lagged        855 non-null    float64\n",
      "dtypes: float64(6), object(7)\n",
      "memory usage: 87.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_Fed_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d74422df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X=df_Fed_merged[[\"text\",\"T5YIFR Lagged\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4366bd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import casual_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "aa026c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=TfidfVectorizer(tokenizer=casual_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e6ab9a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Time_Validation(datafr,labels,test_size=0.2):\n",
    "    train_index = list(range(int(len(datafr)-np.floor(test_size*len(datafr))+1)))\n",
    "    test_index =list(range(int(len(datafr)-np.floor(test_size*len(datafr))+1),len(datafr)))\n",
    "    return datafr.loc[train_index], datafr.loc[test_index],labels[train_index], labels[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a535a77e",
   "metadata": {},
   "source": [
    "# Fed - LGBM - Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6aecfc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a4512866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(855,)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=np.asarray(df_Fed_merged[\"Classes\"].astype(\"int\"))\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5bc15bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X_train, data_X_test, labels_train, labels_test=Time_Validation(data_X,labels,test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "091cc772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(814, 2)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "67c2f451",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iavta\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:489: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    }
   ],
   "source": [
    "vectorizer_fitted=vectorizer.fit(data_X_train[\"text\"])\n",
    "\n",
    "corpus_train=pd.DataFrame(vectorizer_fitted.transform(data_X_train[\"text\"]).toarray())\n",
    "\n",
    "# We've fitted the vectorizer to train data only, and use it to also transform corpus_test\n",
    "corpus_test=pd.DataFrame(vectorizer_fitted.transform(data_X_test[\"text\"]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "06cc98af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45979"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer_fitted.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a26a1120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 814 entries, 0 to 813\n",
      "Columns: 45979 entries, 0 to 45978\n",
      "dtypes: float64(45979)\n",
      "memory usage: 285.5 MB\n"
     ]
    }
   ],
   "source": [
    "corpus_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "95e0ed45",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_train[\"T5YIFR Lagged\"]=data_X_train[\"T5YIFR Lagged\"]\n",
    "corpus_test[\"T5YIFR Lagged\"]=data_X_test[\"T5YIFR Lagged\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "872bf53b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier()"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbmc=LGBMClassifier();\n",
    "lgbmc.fit(corpus_train,labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1dc4d972",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=lgbmc.predict(corpus_test)\n",
    "probabilities=lgbmc.predict_proba(corpus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c662adc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, balanced_accuracy_score,roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5e9e08ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  7],\n",
       "       [ 1,  8,  9],\n",
       "       [ 0,  4, 12]], dtype=int64)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(labels_test, predictions)\n",
    "#  i-th row and j-th column entry indicates the number of samples \n",
    "#  with true label being i-th class and predicted label being j-th class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11ee253",
   "metadata": {},
   "source": [
    "We can see that lgbm tends to predict class 2 (from 0,1 and 2) too many times...\n",
    "This will also be seen with the example sentences below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ddaec985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09722222222222222"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(labels_test, predictions,adjusted=True) \n",
    "# accuracy score for imbalanced classes\n",
    "# 0 for a random classifier\n",
    "# 1 for a perfect classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b0c9fcd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46433994370695136"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(labels_test,probabilities, multi_class=\"ovr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fbab77",
   "metadata": {},
   "source": [
    "This value for roc seems to indicate performance is worse than a random classifier which would get a roc of 0.5...\n",
    "\n",
    "I think I need to do a random grid search to the parameters of the LGBM classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5fc87afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    'Trust us, inflation will be 2%',\n",
    "    'We are unsure whether it will be 2%',\n",
    "    'Inflation will be higher than 2%',\n",
    "    'Inflation will be lower than 2%',\n",
    "]\n",
    "examples_trans=pd.DataFrame(vectorizer_fitted.transform(examples).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "87237ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_trans[\"T5YIFR Lagged\"]=[3,3,3,3] \n",
    "# I've tried several different vectors, no change in results below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a06f8d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Trust us, inflation will be 2% Predicted Class: 2 \n",
      "\n",
      "Sentence: We are unsure whether it will be 2% Predicted Class: 2 \n",
      "\n",
      "Sentence: Inflation will be higher than 2% Predicted Class: 2 \n",
      "\n",
      "Sentence: Inflation will be lower than 2% Predicted Class: 2 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = lgbmc.predict(examples_trans)\n",
    "# 0 ->  no change\n",
    "# 2 -> increased the distance relative to objective of 2\n",
    "# 1 -> decreased the distance relative to objective of 2\n",
    "for sent,pred in zip(examples,predictions):\n",
    "    print(\"Sentence: {0} Predicted Class: {1} \\n\".format(sent,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f441095",
   "metadata": {},
   "source": [
    "# Fed - LGBM - Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6944cceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8ed6d15b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(855,)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target=np.asarray(df_Fed_merged[\"T5YIFR\"])\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f5e62ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X_train, data_X_test, target_train, target_test=Time_Validation(data_X,target,test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "aea2802a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iavta\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:489: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    }
   ],
   "source": [
    "vectorizer_fitted=vectorizer.fit(data_X_train[\"text\"])\n",
    "\n",
    "df_trans_corpus_train=pd.DataFrame(vectorizer_fitted.transform(data_X_train[\"text\"]).toarray())\n",
    "\n",
    "# We've fitted the vectorizer to train data only, and use it to also transform corpus_test\n",
    "df_trans_corpus_test=pd.DataFrame(vectorizer_fitted.transform(data_X_test[\"text\"]).toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "edf0ae9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans_corpus_train[\"T5YIFR Lagged\"]=data_X_train[\"T5YIFR Lagged\"]\n",
    "df_trans_corpus_test[\"T5YIFR Lagged\"]=data_X_test[\"T5YIFR Lagged\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e555dcee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor()"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_reg=LGBMRegressor();\n",
    "lgbm_reg.fit(df_trans_corpus_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "aaee02df",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_reg=lgbm_reg.predict(df_trans_corpus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c86b4574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.6195525721794786\n",
      "0.2170498613750913\n"
     ]
    }
   ],
   "source": [
    "accuracy_reg = lgbm_reg.score(df_trans_corpus_test,target_test)\n",
    "print(accuracy_reg) #\n",
    "\n",
    "rmse = np.sqrt(np.mean((predictions_reg-target_test)**2))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "0c13a4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Trust us, inflation will be 2% Predicted Class: 2.82658007546689 \n",
      "\n",
      "Sentence: We are unsure whether it will be 2% Predicted Class: 2.850074496579208 \n",
      "\n",
      "Sentence: Inflation will be higher than 2% Predicted Class: 2.83186006580961 \n",
      "\n",
      "Sentence: Inflation will be lower than 2% Predicted Class: 2.83186006580961 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "examples_trans=pd.DataFrame(vectorizer_fitted.transform(examples).toarray()) # model was refitted\n",
    "examples_trans[\"T5YIFR Lagged\"]=[3,3,3,3] \n",
    "\n",
    "predictions = lgbm_reg.predict(examples_trans)\n",
    "# 0 ->  no change\n",
    "# 2 -> increased the distance relative to objective of 2\n",
    "# 1 -> decreased the distance relative to objective of 2\n",
    "for sent,pred in zip(examples,predictions):\n",
    "    print(\"Sentence: {0} Predicted Class: {1} \\n\".format(sent,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcfccf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
